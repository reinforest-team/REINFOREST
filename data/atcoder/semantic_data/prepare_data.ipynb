{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "language = 'java'\n",
    "\n",
    "data_file = os.path.join(language, 'with_score.json')\n",
    "data = json.load(open(data_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_problems = {}\n",
    "data_path = os.path.abspath('../raw_data')\n",
    "contests = os.listdir(data_path)\n",
    "for c in contests:\n",
    "    contest_path = os.path.join(data_path, c)\n",
    "    problems = os.listdir(contest_path)\n",
    "    for p in problems:\n",
    "        key = c + \"_\" + p\n",
    "        all_problems[key] = os.path.join(contest_path, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_problems, valid_problems, test_problems = {\n",
    "    'score': data['train_problems'],\n",
    "    'no_score': []\n",
    "}, {\n",
    "    'score': data['val_problems'],\n",
    "    'no_score': [],\n",
    "}, {\n",
    "    'score': data['test_problems'],\n",
    "    'no_score': []\n",
    "},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 9 9\n"
     ]
    }
   ],
   "source": [
    "print(len(train_problems['score']), len(valid_problems['score']), len(test_problems['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361 86 275\n"
     ]
    }
   ],
   "source": [
    "with_score_problem_ids = data['train_problems'] + data['val_problems'] + data['test_problems']\n",
    "all_problem_ids = list(all_problems.keys())\n",
    "wo_score_problem_ids = list(set(all_problem_ids).difference(with_score_problem_ids))\n",
    "\n",
    "print(len(all_problem_ids), len(with_score_problem_ids), len(wo_score_problem_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219 28 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(4000)\n",
    "\n",
    "def divide_problems(data):\n",
    "    np.random.shuffle(data)\n",
    "    l = len(data)\n",
    "    test = int(np.ceil(l * 0.1))\n",
    "    valid = test\n",
    "    return data[(test+valid):], data[test:(test+valid)], data[:test]\n",
    "\n",
    "trwo, vwo, two = divide_problems(wo_score_problem_ids)\n",
    "\n",
    "print(len(trwo), len(vwo), len(two))\n",
    "train_problems['no_score'] = trwo\n",
    "valid_problems['no_score'] = vwo\n",
    "test_problems['no_score'] = two\n",
    "\n",
    "problem_ids = {\n",
    "    'train': train_problems,\n",
    "    'valid': valid_problems,\n",
    "    'test': test_problems\n",
    "}\n",
    "\n",
    "with open(os.path.join(language, 'problem_ids.json'), 'w') as f:\n",
    "    json.dump(problem_ids, f, indent=4)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "without_score_folder = os.path.join(language, \"wo_score\")\n",
    "os.makedirs(without_score_folder, exist_ok=True)\n",
    "\n",
    "with_score_folder = os.path.join(language, 'with_score')\n",
    "os.makedirs(with_score_folder, exist_ok=True)\n",
    "\n",
    "full_score_folder = os.path.join(language, 'full_score')\n",
    "os.makedirs(full_score_folder, exist_ok=True)\n",
    "\n",
    "train_with, valid_with, test_with = data['train_data'], data['val_data'], data['test_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "valid\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for name, data in [\n",
    "    ('train', train_with), \n",
    "    ('valid', valid_with), \n",
    "    ('test', test_with)\n",
    "]:\n",
    "    print(name)\n",
    "    data_file = open(os.path.join(with_score_folder, name + \".jsonl\"), \"w\")\n",
    "    for d in data:\n",
    "        d['code'] = d['base_sample_code']\n",
    "        d.pop('base_sample_code')\n",
    "        data_file.write(json.dumps(d) + \"\\n\")\n",
    "    data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Codes: 0\t4.83\t5\n",
      "Negative Codes: 5\t5.0\t5\n",
      "====================================================================================================\n",
      "Positive Codes: 0\t4.91\t5\n",
      "Negative Codes: 5\t5.0\t5\n",
      "====================================================================================================\n",
      "Positive Codes: 0\t110.79\t202\n",
      "Negative Codes: 1950\t2041.21\t2152\n",
      "====================================================================================================\n",
      "7455 1448 1698\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Union, Tuple\n",
    "import copy\n",
    "\n",
    "\n",
    "def read_files(\n",
    "    directory: str,\n",
    "    ext: str\n",
    "):\n",
    "    return {\n",
    "        p: open(\n",
    "            os.path.join(directory, p)\n",
    "        ).read() for  p in os.listdir(directory) if p.endswith(ext)\n",
    "    }\n",
    "\n",
    "def sample_code(\n",
    "    pid: str,\n",
    "    samples: Union[Dict[str, str], List[Tuple[str, Dict[str, str]]]],\n",
    "    n: int,\n",
    "    score: float = 0.\n",
    "):\n",
    "    modified_samples = {}\n",
    "    if isinstance(samples, List):\n",
    "        for nid, nsamples in samples:\n",
    "            for p in nsamples.keys():\n",
    "                modified_samples[nid + \"_\" + p] = nsamples[p]\n",
    "    else:\n",
    "        for p in samples:\n",
    "            modified_samples[pid + \"_\" + p] = samples[p]\n",
    "    samples_keys = list(modified_samples.keys())\n",
    "    if len(samples_keys) == 0:\n",
    "        return []\n",
    "    if len(samples_keys) < n:\n",
    "        chosen_keys = samples_keys\n",
    "    else:\n",
    "        chosen_keys = np.random.choice(samples_keys, size=n)\n",
    "    return [\n",
    "        {\n",
    "            'code': modified_samples[k],\n",
    "            'comparison_sample_name': k,\n",
    "            'score': score\n",
    "        } for k in chosen_keys\n",
    "    ]\n",
    "\n",
    "def prepare_without_score(\n",
    "    problem_to_path: Dict[str, str], \n",
    "    problem_ids: List[str], \n",
    "    src_ext: str, \n",
    "    tgt_ext:str,\n",
    "    n: int\n",
    "):\n",
    "    data = []\n",
    "    pid_to_code = {\n",
    "        p: {\n",
    "            src_ext: read_files(\n",
    "                directory=problem_to_path[p], \n",
    "                ext=src_ext\n",
    "            ),\n",
    "            tgt_ext: read_files(\n",
    "                directory=problem_to_path[p], \n",
    "                ext=tgt_ext\n",
    "            )\n",
    "        } for p in problem_ids\n",
    "    }\n",
    "    pos_lengths = []\n",
    "    neg_lengths = []\n",
    "    for pid in problem_ids:\n",
    "        source_codes = pid_to_code[pid][src_ext]\n",
    "        positive_samples = pid_to_code[pid][tgt_ext]\n",
    "        negative_pids = copy.copy(problem_ids)\n",
    "        negative_pids.remove(pid)\n",
    "        negative_samples = [(nid, pid_to_code[nid][tgt_ext]) for nid in negative_pids]\n",
    "        for c in source_codes.keys():\n",
    "            source_code = source_codes[c]\n",
    "            base_sample_name = pid + '_' + c\n",
    "            positive_codes = sample_code(pid, positive_samples, n=n)\n",
    "            pos_lengths.append(len(positive_codes))\n",
    "            negative_codes = sample_code(pid, negative_samples, n=n)\n",
    "            neg_lengths.append(len(negative_codes))\n",
    "            data.append({\n",
    "                'base_sample_name': base_sample_name,\n",
    "                'code': source_code,\n",
    "                'positives': positive_codes,\n",
    "                'negatives': negative_codes\n",
    "            })\n",
    "    print(f\"Positive Codes: {round(np.min(pos_lengths).item(), 2)}\\t{round(np.mean(pos_lengths).item(), 2)}\\t{round(np.max(pos_lengths).item(), 2)}\")\n",
    "    print(f\"Negative Codes: {round(np.min(neg_lengths).item(), 2)}\\t{round(np.mean(neg_lengths).item(), 2)}\\t{round(np.max(neg_lengths).item(), 2)}\")\n",
    "    print(\"=\" * 100)\n",
    "    return data\n",
    "    \n",
    "train_wo = prepare_without_score(\n",
    "    problem_to_path=all_problems,\n",
    "    problem_ids=train_problems['no_score'],\n",
    "    src_ext='py' if language=='python' else 'java',\n",
    "    tgt_ext='py' if language=='java' else 'java',\n",
    "    n=5\n",
    ")\n",
    "\n",
    "valid_wo = prepare_without_score(\n",
    "    problem_to_path=all_problems,\n",
    "    problem_ids=valid_problems['no_score'],\n",
    "    src_ext='py' if language=='python' else 'java',\n",
    "    tgt_ext='py' if language=='java' else 'java',\n",
    "    n=5\n",
    ")\n",
    "\n",
    "test_wo = prepare_without_score(\n",
    "    problem_to_path=all_problems,\n",
    "    problem_ids=test_problems['no_score'] + test_problems['score'],\n",
    "    src_ext='py' if language=='python' else 'java',\n",
    "    tgt_ext='py' if language=='java' else 'java',\n",
    "    n=1000000\n",
    ")\n",
    "print(len(train_wo), len(valid_wo), len(test_wo)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "valid\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "for name, data in [\n",
    "    ('train', train_wo), \n",
    "    ('valid', valid_wo), \n",
    "    ('test', test_wo)\n",
    "]:\n",
    "    print(name)\n",
    "    data_file = open(os.path.join(without_score_folder, name + \".jsonl\"), \"w\")\n",
    "    for d in data:\n",
    "        data_file.write(json.dumps(d) + \"\\n\")\n",
    "    data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "valid\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "train = train_wo + train_with\n",
    "valid = valid_wo + valid_with\n",
    "np.random.shuffle(train)\n",
    "np.random.shuffle(valid)\n",
    "for name, data in [\n",
    "    ('train', train), \n",
    "    ('valid', valid), \n",
    "    ('test', test_wo)\n",
    "]:\n",
    "    print(name)\n",
    "    data_file = open(os.path.join(full_score_folder, name + \".jsonl\"), \"w\")\n",
    "    for d in data:\n",
    "        data_file.write(json.dumps(d) + \"\\n\")\n",
    "    data_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-ranker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6faf57c0281c9f55724b7ff7062ea373deef8d2d2dfcd72e3d788a4bc1720ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
